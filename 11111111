# -*- coding: utf-8 -*-

import gzip,re,requests,time,random
from multiprocessing import Pool
import mysql.connector

#def ungzip(data):
   # try:        # 尝试解压
       # print('正在解压.....')
       # data = gzip.decompress(data)
        #print('解压完毕!')
   # except:
      #  print('未经压缩, 无需解压')
  #  return data
	
#@asyncio.coroutine
#def test(name,types,num,court,dates,url,docid,proced,cause,area,yiju,content):
#    p=panjueshu(name=name,cause=cause,docid=docid,area=area,proced=proced,types=types,num=num,court=court,dates=dates,yiju=yiju,content=content,url=url)
#    yield from p.save()

#loop.run_until_complete(create(loop))
class Panjueshu(object):
    def __init__(self):
        self.proxy_ip=None
        self.ip_time=time.time()
        #self.count=0
        self.url_list='http://wenshu.court.gov.cn/List/ListContent'
        self.user_agent = ['Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',
                       'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.95 Safari/537.36',
                       'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; rv:11.0) like Gecko)',
                       'Mozilla/5.0 (Windows; U; Windows NT 5.2) Gecko/2008070208 Firefox/3.0.1',
                       'Mozilla/5.0 (Windows; U; Windows NT 5.1) Gecko/20070309 Firefox/2.0.0.3',
                       'Mozilla/5.0 (Windows; U; Windows NT 5.1) Gecko/20070803 Firefox/1.5.0.12',
                       'Opera/9.27 (Windows NT 5.2; U; zh-cn)',
                       'Mozilla/5.0 (Macintosh; PPC Mac OS X; U; en) Opera 8.0',
                       'Opera/8.0 (Macintosh; PPC Mac OS X; U; en)',
                       'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.12) Gecko/20080219 Firefox/2.0.0.12 Navigator/9.0.0.6',
                       'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; Win64; x64; Trident/4.0)',
                       'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0)',
                       'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.2; .NET4.0C; .NET4.0E)',
                       'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Maxthon/4.0.6.2000 Chrome/26.0.1410.43 Safari/537.1 ',
                       'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.2; .NET4.0C; .NET4.0E; QQBrowser/7.3.9825.400)',
                       'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0 ',
                       'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.92 Safari/537.1 LBBROWSER',
                       'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0; BIDUBrowser 2.x)',
                       'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/3.0 Safari/536.11']
        self.get_ip = ['125.88.74.122:81',
                       '183.95.80.165:8080',
                       '59.37.160.57:8081',
                       '124.133.230.254:80',
                       '183.78.183.156:82',
                       '124.88.67.83:843',
                       '42.81.58.199:80',
                       '124.88.67.9:80',
                       '180.167.34.187:80',
                       '183.78.183.156:82',
                       '125.88.74.122:85',
                       '124.88.67.22:83',
                       '14.152.93.79:8080',
                       '120.9.13.2:8888',
                       '182.38.36.42:8998',
                       '122.96.59.98:82',
                       '117.95.19.112:8998',
                       '14.127.200.59:8081',
                       '221.3.6.2:8081',
                       '182.112.128.115:80',
                       '124.88.67.9:843',
                       '171.8.79.143:8080',
                       '183.57.249.97:8081',
                       '180.136.83.16:8998',
                       '220.174.236.211:80',
                       '124.88.67.17:83',
                       '124.88.67.54:82',
                       '42.81.58.199:80',
                       '183.165.150.216:8998'
                       ]
    def get_content(self,num_index):
        str_index=str(num_index)
        #print(str_index)
        data={'Param':'裁判年份:2016',
	'Page':'20',
	'Order':'法院层级',
	'Index':str_index,
	'Direction':'asc'

	}
	#send_data=parse.urlencode(data).encode('utf-8')
        headers={'X-Requested-With': 'XMLHttpRequest',
	'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
	'User-Agent': random.choice(self.user_agent),
	'Connection': 'keep-alive','Host': 'wenshu.court.gov.cn'
	}
        #print(headers)
        #print(time.time())
        if (int(time.time())-self.ip_time) > 30 or not self.proxy_ip:
            self.proxy_ip={'http':'http://%s'%random.choice(self.get_ip)}
            self.ip_time=int(time.time())
        print(str_index)
        print(self.proxy_ip)
        try:
            resp=requests.post(self.url_list,data=data,headers=headers,proxies=self.proxy_ip,timeout=40)
            respons=resp.text
            pattern=re.compile(r'{\\"裁判要旨段原文\\":\\"(.*?)\\",\\"案件类型\\":\\"(.*?)\\",\\"裁判日期\\":\\"(.*?)\\",\\"案件名称\\":\\"(.*?)\\",\\"文书ID\\":\\"(.*?)\\",\\"审判程序\\":\\"(.*?)\\",\\"案号\\":\\"(.*?)\\",\\"法院名称\\":\\"(.*?)\\"}')
            list_info = re.findall(pattern,respons)
            if list_info:
                print('%s ok'%str_index)
            else:
                print('%s no'%str_index)
                self.proxy_ip = {'http':'http://%s'%random.choice(self.get_ip)}
        except:
            print('%s no'%str_index)
            self.proxy_ip = {'http':'http://%s'%random.choice(self.get_ip)}
        for info in list_info:
            cause = info[0]
            types = info[1]
            dates = info[2]
            name = info[3]
            docid = info[4]
            proced = info[5]
            num = info[6]
            court = info[7]
            url='http://wenshu.court.gov.cn/content/content?DocID=%s'%info[4]
	    #url_content = 'http://wenshu.court.gov.cn/CreateContentJS/CreateContentJS.aspx?DocID=%s'%info
	    #resp_content=requests.get(url_content).text
            #loop.run_until_complete(test(name,types,num,court,dates,url,docid,proced))
            conn = mysql.connector.connect(user='root', password='password', database='caipan')
            cursor = conn.cursor()
            cursor.execute('insert into panjueshu (name,docid,proced,types,url,num,court,dates,cause) values (%s,%s,%s,%s,%s,%s,%s,%s,%s)', [name,docid,proced,types,url,num,court,dates,cause])
            conn.commit()
            cursor.close()
            conn.close()
        #print(self.count)
def duoye_1(page):
    panjue=Panjueshu()
    for num in range(page-10,page):
        time.sleep(random.random()+0.5)
        try:
            panjue.get_content(num)
        except:
            try:
                print('%s下载失败,重新下载'%num)
                panjue.get_content(num)
            except:
                try:
                    print('%s再次下载失败,尝试第三次下载'%num)
                    panjue.get_content(num)
                except:
                    print('%s多次尝试无效，放弃！'%num)
            
        #print(5)
if __name__=='__main__':
    #loop = asyncio.get_event_loop()
    p=Pool(4)
    #print(1)
    for i in range(1,7):
        p.apply_async(duoye_1,args=(i*10+1,))
    print('Waiting for all subprocesses done...')
    p.close()
    p.join()
    print('All subprocesses done.')


