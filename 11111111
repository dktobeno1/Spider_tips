# -*- coding: utf-8 -*-

import gzip,re,requests,time,random
from multiprocessing import Pool
import mysql.connector

#def ungzip(data):
   # try:        # 尝试解压
       # print('正在解压.....')
       # data = gzip.decompress(data)
        #print('解压完毕!')
   # except:
      #  print('未经压缩, 无需解压')
  #  return data
	
#@asyncio.coroutine
#def test(name,types,num,court,dates,url,docid,proced,cause,area,yiju,content):
#    p=panjueshu(name=name,cause=cause,docid=docid,area=area,proced=proced,types=types,num=num,court=court,dates=dates,yiju=yiju,content=content,url=url)
#    yield from p.save()

#loop.run_until_complete(create(loop))
class Panjueshu(object):
    def __init__(self):
        self.proxy_ip=None
        self.ip_time=time.time()
        #self.count=0
        self.url_list='http://wenshu.court.gov.cn/List/ListContent'
        self.user_agent = ['Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36 SE 2.X MetaSr 1.0',
                    'Mozilla/5.0 (Macintosh; PPC Mac OS X; U; en) Opera 8.0',
                    'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0',
                    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 ']
        self.get_ip = ['125.88.74.122:81',
                       '183.95.80.165:8080',
                       '59.37.160.57:8081',
                       '124.133.230.254:80',
                       '183.78.183.156:82',
                       '124.88.67.83:843',
                       '42.81.58.199:80',
                       '124.88.67.9:80',
                       '180.167.34.187:80',
                       '183.78.183.156:82',
                       '125.88.74.122:85',
                       '124.88.67.22:83',
                       
                       ]
    def get_content(self,num_index):
        str_index=str(num_index)
        #print(str_index)
        data={'Param':'裁判年份:2016',
	'Page':'20',
	'Order':'法院层级',
	'Index':str_index,
	'Direction':'asc'

	}
	#send_data=parse.urlencode(data).encode('utf-8')
        headers={'X-Requested-With': 'XMLHttpRequest',
	'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
	'User-Agent': random.choice(self.user_agent),
	'Connection': 'keep-alive','Host': 'wenshu.court.gov.cn'
	}
        #print(headers)
        #print(time.time())
        if (int(time.time())-self.ip_time) > 15 or not self.proxy_ip:
            self.proxy_ip={'http':'http://%s'%random.choice(self.get_ip)}
            self.ip_time=int(time.time())
        print(str_index)
        print(self.proxy_ip)
        try:
            resp=requests.post(self.url_list,data=data,headers=headers,proxies=self.proxy_ip,timeout=40)
        except:
            self.proxy_ip = {'http':'http://%s'%random.choice(self.get_ip)}
        respons=resp.text
        pattern=re.compile(r'{\\"裁判要旨段原文\\":\\"(.*?)\\",\\"案件类型\\":\\"(.*?)\\",\\"裁判日期\\":\\"(.*?)\\",\\"案件名称\\":\\"(.*?)\\",\\"文书ID\\":\\"(.*?)\\",\\"审判程序\\":\\"(.*?)\\",\\"案号\\":\\"(.*?)\\",\\"法院名称\\":\\"(.*?)\\"}')
        list_info = re.findall(pattern,respons)
        if list_info:
            print('ok')
        else:
            print('no')
        for info in list_info:
            cause = info[0]
            types = info[1]
            dates = info[2]
            name = info[3]
            docid = info[4]
            proced = info[5]
            num = info[6]
            court = info[7]
            url='http://wenshu.court.gov.cn/content/content?DocID=%s'%info[4]
	    #url_content = 'http://wenshu.court.gov.cn/CreateContentJS/CreateContentJS.aspx?DocID=%s'%info
	    #resp_content=requests.get(url_content).text
            #loop.run_until_complete(test(name,types,num,court,dates,url,docid,proced))
            conn = mysql.connector.connect(user='root', password='', database='caipan')
            cursor = conn.cursor()
            cursor.execute('insert into panjueshu (name,docid,proced,types,url,num,court,dates,cause) values (%s,%s,%s,%s,%s,%s,%s,%s,%s)', [name,docid,proced,types,url,num,court,dates,cause])
            conn.commit()
            cursor.close()
            conn.close()    
            #self.count+=1
        #print(self.count)
def duoye_1(page):
    panjue=Panjueshu()
    for num in range(page-10,page):
        time.sleep(1*(random.random()+0.5))
        try:
        #print('time')
            panjue.get_content(num)
        except:
            print('%s下载失败'%num)
        #print(5)
if __name__=='__main__':
    #loop = asyncio.get_event_loop()
    p=Pool(3)
    #print(1)
    for i in range(1,4):
        p.apply_async(duoye_1,args=(i*10+1,))
    print('Waiting for all subprocesses done...')
    p.close()
    p.join()
    print('All subprocesses done.')



