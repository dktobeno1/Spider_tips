import scrapy
from myscrapy.items import BookItem

class BookinfoSpider(scrapy.Spider):
    name='bookinfo'
    allowed_domains=['allitebooks.com','amazon.com']
    start_urls=['http://www.allitebooks.com/security/'
        ]
    def parse(self,response):
        #num_pages = int(response.xpath('//a[@title="Last Page â†’"]/text()').extract())
        num_pages=15
        base_url = "http://www.allitebooks.com/security/page/{0}/"
        for page in range(1, num_pages+1):
            yield scrapy.Request(base_url.format(page),callback=self.parse_page)

    def parse_page(self,response):
        list_bookurl=response.xpath('//div/header/h2/a/@href').extract()
        for bookurl in list_bookurl:
            yield scrapy.Request(bookurl,callback=self.parse_bookinfo)

    def parse_bookinfo(self,response):
        item=BookItem()
        title=response.xpath('//h1[@class="single-title"]/text()').extract()[0]
        isbn=response.xpath('//dd[2]/text()').extract()[0]
        item['title']=title
        item['isbn']=isbn
        amazon_search_url = 'https://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Daps&field-keywords=' + isbn
        yield scrapy.Request(amazon_search_url,headers={'User-agent': 'Mozilla/5.0'},callback=self.parse_price,meta={'item':item})

    def parse_price(self,response):
        item=response.meta['item']
        price=response.xpath('//span/text()').re(r'\$[0-9]+\.[0-9]{2}?')[0]
        item['price']=price
        yield item
